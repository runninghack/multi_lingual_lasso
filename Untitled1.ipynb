{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c953166b6410>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-c953166b6410>\u001b[0m in \u001b[0;36mcreate_df\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'embersGeoCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Brazil'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mdf_twitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mdf_aggregated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m#df.loc[df['date'].idxmax()]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json as js\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6c631db9bc43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-6c631db9bc43>\u001b[0m in \u001b[0;36mcreate_df\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'embersGeoCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Brazil'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mdf_twitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mdf_aggregated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;31m#df.loc[df['date'].idxmax()]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_aggregated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json as js\n",
    "import time\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5aa617c0c696>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5aa617c0c696>\u001b[0m in \u001b[0;36mcreate_df\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'embersGeoCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Brazil'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mdf_twitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mdf_aggregated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_twitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;31m#df.loc[df['date'].idxmax()]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_aggregated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5aa617c0c696>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m((key,))\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'embersGeoCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Brazil'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mdf_twitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mdf_aggregated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_twitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;31m#df.loc[df['date'].idxmax()]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_aggregated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json as js\n",
    "import time\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     medo  ataque  armar  emboscada  \\\n",
      "date                                                                  \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)     0       0      0          0   \n",
      "\n",
      "                                     interrogatório  recrudescência  oposição  \\\n",
      "date                                                                            \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)               0               0         0   \n",
      "\n",
      "                                     essencial  cooperativa  pobreza   ...    \\\n",
      "date                                                                   ...     \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)          0            0        0   ...     \n",
      "\n",
      "                                     guarani  vice  vigília  perseguição  \\\n",
      "date                                                                       \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)        0     0        0            0   \n",
      "\n",
      "                                     perigo  relação  desgosto  promotor  \\\n",
      "date                                                                       \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)       0        0         0         0   \n",
      "\n",
      "                                     rural  manter  \n",
      "date                                                \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)      0       0  \n",
      "\n",
      "[1 rows x 624 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "import time\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medo              0\n",
       "ataque            0\n",
       "armar             0\n",
       "emboscada         0\n",
       "interrogatório    0\n",
       "recrudescência    0\n",
       "oposição          0\n",
       "essencial         0\n",
       "cooperativa       0\n",
       "pobreza           0\n",
       "privar            0\n",
       "irregularidade    0\n",
       "libertar          0\n",
       "pedra             0\n",
       "arbitrário        0\n",
       "rebelde           0\n",
       "contribuinte      0\n",
       "tortura           0\n",
       "reforma           0\n",
       "armadilha         0\n",
       "injustiça         0\n",
       "colapso           0\n",
       "marcha            0\n",
       "amotinamiento     0\n",
       "encarar           0\n",
       "comunidade        0\n",
       "operação          0\n",
       "ganadeiro         0\n",
       "posto             0\n",
       "decisão           0\n",
       "                 ..\n",
       "presença          0\n",
       "produtor          0\n",
       "extremo           0\n",
       "mineiro           0\n",
       "autonomia         0\n",
       "convite           0\n",
       "pesquisa          0\n",
       "Fernando          0\n",
       "plantação         0\n",
       "ativar            0\n",
       "humilhar          0\n",
       "cidadão           0\n",
       "extracção         0\n",
       "membro            0\n",
       "participante      0\n",
       "incluir           0\n",
       "problema          0\n",
       "um                0\n",
       "intimidar         0\n",
       "alteração         0\n",
       "guarani           0\n",
       "vice              0\n",
       "vigília           0\n",
       "perseguição       0\n",
       "perigo            0\n",
       "relação           0\n",
       "desgosto          0\n",
       "promotor          0\n",
       "rural             0\n",
       "manter            0\n",
       "Name: (2014, 12, 31, 0, 0, 0, 2, 365, -1), dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[df1['medo'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     medo  ataque  armar  emboscada  \\\n",
      "date                                                                  \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)      0       0      0          0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)     0       0      0          0   \n",
      "\n",
      "                                     interrogatório  recrudescência  oposição  \\\n",
      "date                                                                            \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)                0               0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)               0               0         0   \n",
      "\n",
      "                                     essencial  cooperativa  pobreza   ...    \\\n",
      "date                                                                   ...     \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)           0            0        0   ...     \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)          0            0        0   ...     \n",
      "\n",
      "                                     guarani  vice  vigília  perseguição  \\\n",
      "date                                                                       \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)         0     0        0            0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)        0     0        0            0   \n",
      "\n",
      "                                     perigo  relação  desgosto  promotor  \\\n",
      "date                                                                       \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)        0        0         0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)       0        0         0         0   \n",
      "\n",
      "                                     rural  manter  \n",
      "date                                                \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)       0       0  \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)      0       0  \n",
      "\n",
      "[2 rows x 624 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "import time\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     medo  ataque  armar  emboscada  \\\n",
      "date                                                                  \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)      0       0      0          0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)      0       0      0          0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)     0       0      0          0   \n",
      "\n",
      "                                     interrogatório  recrudescência  oposição  \\\n",
      "date                                                                            \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)                0               0         0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)                0               0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)               0               0         0   \n",
      "\n",
      "                                     essencial  cooperativa  pobreza   ...    \\\n",
      "date                                                                   ...     \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)           0            0        0   ...     \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)           0            0        0   ...     \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)          0            0        0   ...     \n",
      "\n",
      "                                     guarani  vice  vigília  perseguição  \\\n",
      "date                                                                       \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)         0     0        0            0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)         0     0        0            0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)        0     0        0            0   \n",
      "\n",
      "                                     perigo  relação  desgosto  promotor  \\\n",
      "date                                                                       \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)        0        0         0         0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)        0        0         0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)       0        0         0         0   \n",
      "\n",
      "                                     rural  manter  \n",
      "date                                                \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)       0       0  \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)       0       0  \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)      0       0  \n",
      "\n",
      "[3 rows x 624 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "import time\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     medo  ataque  armar  emboscada  \\\n",
      "date                                                                  \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)      0       0      0          0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)      0       0      0          0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)     0       0      0          0   \n",
      "\n",
      "                                     interrogatório  recrudescência  oposição  \\\n",
      "date                                                                            \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)                0               0         0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)                0               0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)               0               0         0   \n",
      "\n",
      "                                     essencial  cooperativa  pobreza   ...    \\\n",
      "date                                                                   ...     \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)           0            0        0   ...     \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)           0            0        0   ...     \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)          0            0        0   ...     \n",
      "\n",
      "                                     guarani  vice  vigília  perseguição  \\\n",
      "date                                                                       \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)         0     0        0            0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)         0     0        0            0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)        0     0        0            0   \n",
      "\n",
      "                                     perigo  relação  desgosto  promotor  \\\n",
      "date                                                                       \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)        0        0         0         0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)        0        0         0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)       0        0         0         0   \n",
      "\n",
      "                                     rural  manter  \n",
      "date                                                \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)       0       0  \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)       0       0  \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)      0       0  \n",
      "\n",
      "[3 rows x 624 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "import time\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     medo  ataque  armar  emboscada  \\\n",
      "date                                                                  \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)      0       0      0          0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)      0       0      0          0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)     0       0      0          0   \n",
      "\n",
      "                                     interrogatório  recrudescência  oposição  \\\n",
      "date                                                                            \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)                0               0         0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)                0               0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)               0               0         0   \n",
      "\n",
      "                                     essencial  cooperativa  pobreza   ...    \\\n",
      "date                                                                   ...     \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)           0            0        0   ...     \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)           0            0        0   ...     \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)          0            0        0   ...     \n",
      "\n",
      "                                     guarani  vice  vigília  perseguição  \\\n",
      "date                                                                       \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)         0     0        0            0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)         0     0        0            0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)        0     0        0            0   \n",
      "\n",
      "                                     perigo  relação  desgosto  promotor  \\\n",
      "date                                                                       \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)        0        0         0         0   \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)        0        0         0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)       0        0         0         0   \n",
      "\n",
      "                                     rural  manter  \n",
      "date                                                \n",
      "(2014, 12, 1, 0, 0, 0, 0, 335, -1)       0       0  \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)       0       0  \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)      0       0  \n",
      "\n",
      "[3 rows x 624 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "import time\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     medo  ataque  armar  emboscada  \\\n",
      "date                                                                  \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)      0       0      0          0   \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)     0       0      0          0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)     0       0      0          0   \n",
      "\n",
      "                                     interrogatório  recrudescência  oposição  \\\n",
      "date                                                                            \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)                0               0         0   \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)               0               0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)               0               0         0   \n",
      "\n",
      "                                     essencial  cooperativa  pobreza   ...    \\\n",
      "date                                                                   ...     \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)           0            0        0   ...     \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)          0            0        0   ...     \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)          0            0        0   ...     \n",
      "\n",
      "                                     guarani  vice  vigília  perseguição  \\\n",
      "date                                                                       \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)         0     0        0            0   \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)        0     0        0            0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)        0     0        0            0   \n",
      "\n",
      "                                     perigo  relação  desgosto  promotor  \\\n",
      "date                                                                       \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)        0        0         0         0   \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)       0        0         0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)       0        0         0         0   \n",
      "\n",
      "                                     rural  manter  \n",
      "date                                                \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)       0       0  \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)      0       0  \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)      0       0  \n",
      "\n",
      "[3 rows x 624 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "import time\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     medo  ataque  armar  emboscada  \\\n",
      "date                                                                  \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)      0       0      0          0   \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)     0       0      0          0   \n",
      "(2014, 12, 16, 0, 0, 0, 1, 350, -1)     0       0      0          0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)     0       0      0          0   \n",
      "\n",
      "                                     interrogatório  recrudescência  oposição  \\\n",
      "date                                                                            \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)                0               0         0   \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)               0               0         0   \n",
      "(2014, 12, 16, 0, 0, 0, 1, 350, -1)               0               0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)               0               0         0   \n",
      "\n",
      "                                     essencial  cooperativa  pobreza   ...    \\\n",
      "date                                                                   ...     \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)           0            0        0   ...     \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)          0            0        0   ...     \n",
      "(2014, 12, 16, 0, 0, 0, 1, 350, -1)          0            0        0   ...     \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)          0            0        0   ...     \n",
      "\n",
      "                                     guarani  vice  vigília  perseguição  \\\n",
      "date                                                                       \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)         0     0        0            0   \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)        0     0        0            0   \n",
      "(2014, 12, 16, 0, 0, 0, 1, 350, -1)        0     0        0            0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)        0     0        0            0   \n",
      "\n",
      "                                     perigo  relação  desgosto  promotor  \\\n",
      "date                                                                       \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)        0        0         0         0   \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)       0        0         0         0   \n",
      "(2014, 12, 16, 0, 0, 0, 1, 350, -1)       0        0         0         0   \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)       0        0         0         0   \n",
      "\n",
      "                                     rural  manter  \n",
      "date                                                \n",
      "(2014, 12, 3, 0, 0, 0, 2, 337, -1)       0       0  \n",
      "(2014, 12, 15, 0, 0, 0, 0, 349, -1)      0       0  \n",
      "(2014, 12, 16, 0, 0, 0, 1, 350, -1)      0       0  \n",
      "(2014, 12, 31, 0, 0, 0, 2, 365, -1)      0       0  \n",
      "\n",
      "[4 rows x 624 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "import time\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [time.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c46a7c532875>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1967\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1968\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1969\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1971\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1974\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1975\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3210\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3211\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3212\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[0;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1759\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3979)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3843)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12265)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12216)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "max(df1['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medo</th>\n",
       "      <th>ataque</th>\n",
       "      <th>armar</th>\n",
       "      <th>emboscada</th>\n",
       "      <th>interrogatório</th>\n",
       "      <th>recrudescência</th>\n",
       "      <th>oposição</th>\n",
       "      <th>essencial</th>\n",
       "      <th>cooperativa</th>\n",
       "      <th>pobreza</th>\n",
       "      <th>...</th>\n",
       "      <th>guarani</th>\n",
       "      <th>vice</th>\n",
       "      <th>vigília</th>\n",
       "      <th>perseguição</th>\n",
       "      <th>perigo</th>\n",
       "      <th>relação</th>\n",
       "      <th>desgosto</th>\n",
       "      <th>promotor</th>\n",
       "      <th>rural</th>\n",
       "      <th>manter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(2014, 12, 3, 0, 0, 0, 2, 337, -1)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2014, 12, 15, 0, 0, 0, 0, 349, -1)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2014, 12, 16, 0, 0, 0, 1, 350, -1)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2014, 12, 31, 0, 0, 0, 2, 365, -1)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     medo  ataque  armar  emboscada  \\\n",
       "date                                                                  \n",
       "(2014, 12, 3, 0, 0, 0, 2, 337, -1)      0       0      0          0   \n",
       "(2014, 12, 15, 0, 0, 0, 0, 349, -1)     0       0      0          0   \n",
       "(2014, 12, 16, 0, 0, 0, 1, 350, -1)     0       0      0          0   \n",
       "(2014, 12, 31, 0, 0, 0, 2, 365, -1)     0       0      0          0   \n",
       "\n",
       "                                     interrogatório  recrudescência  oposição  \\\n",
       "date                                                                            \n",
       "(2014, 12, 3, 0, 0, 0, 2, 337, -1)                0               0         0   \n",
       "(2014, 12, 15, 0, 0, 0, 0, 349, -1)               0               0         0   \n",
       "(2014, 12, 16, 0, 0, 0, 1, 350, -1)               0               0         0   \n",
       "(2014, 12, 31, 0, 0, 0, 2, 365, -1)               0               0         0   \n",
       "\n",
       "                                     essencial  cooperativa  pobreza   ...    \\\n",
       "date                                                                   ...     \n",
       "(2014, 12, 3, 0, 0, 0, 2, 337, -1)           0            0        0   ...     \n",
       "(2014, 12, 15, 0, 0, 0, 0, 349, -1)          0            0        0   ...     \n",
       "(2014, 12, 16, 0, 0, 0, 1, 350, -1)          0            0        0   ...     \n",
       "(2014, 12, 31, 0, 0, 0, 2, 365, -1)          0            0        0   ...     \n",
       "\n",
       "                                     guarani  vice  vigília  perseguição  \\\n",
       "date                                                                       \n",
       "(2014, 12, 3, 0, 0, 0, 2, 337, -1)         0     0        0            0   \n",
       "(2014, 12, 15, 0, 0, 0, 0, 349, -1)        0     0        0            0   \n",
       "(2014, 12, 16, 0, 0, 0, 1, 350, -1)        0     0        0            0   \n",
       "(2014, 12, 31, 0, 0, 0, 2, 365, -1)        0     0        0            0   \n",
       "\n",
       "                                     perigo  relação  desgosto  promotor  \\\n",
       "date                                                                       \n",
       "(2014, 12, 3, 0, 0, 0, 2, 337, -1)        0        0         0         0   \n",
       "(2014, 12, 15, 0, 0, 0, 0, 349, -1)       0        0         0         0   \n",
       "(2014, 12, 16, 0, 0, 0, 1, 350, -1)       0        0         0         0   \n",
       "(2014, 12, 31, 0, 0, 0, 2, 365, -1)       0        0         0         0   \n",
       "\n",
       "                                     rural  manter  \n",
       "date                                                \n",
       "(2014, 12, 3, 0, 0, 0, 2, 337, -1)       0       0  \n",
       "(2014, 12, 15, 0, 0, 0, 0, 349, -1)      0       0  \n",
       "(2014, 12, 16, 0, 0, 0, 1, 350, -1)      0       0  \n",
       "(2014, 12, 31, 0, 0, 0, 2, 365, -1)      0       0  \n",
       "\n",
       "[4 rows x 624 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medo              (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "ataque            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "armar             (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "emboscada         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "interrogatório    (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "recrudescência    (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "oposição          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "essencial         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "cooperativa       (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "pobreza           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "privar            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "irregularidade    (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "libertar          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "pedra             (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "arbitrário        (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "rebelde           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "contribuinte      (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "tortura           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "reforma           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "armadilha         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "injustiça         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "colapso           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "marcha            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "amotinamiento     (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "encarar           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "comunidade        (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "operação          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "ganadeiro         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "posto             (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "decisão           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "                                 ...                \n",
       "presença          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "produtor          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "extremo           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "mineiro           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "autonomia         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "convite           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "pesquisa          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "Fernando          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "plantação         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "ativar            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "humilhar          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "cidadão           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "extracção         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "membro            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "participante      (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "incluir           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "problema          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "um                (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "intimidar         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "alteração         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "guarani           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "vice              (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "vigília           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "perseguição       (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "perigo            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "relação           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "desgosto          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "promotor          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "rural             (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "manter            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d691d87cf6a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'DataFrame' is not defined"
     ]
    }
   ],
   "source": [
    "DataFrame.idxmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medo              (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "ataque            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "armar             (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "emboscada         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "interrogatório    (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "recrudescência    (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "oposição          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "essencial         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "cooperativa       (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "pobreza           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "privar            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "irregularidade    (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "libertar          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "pedra             (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "arbitrário        (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "rebelde           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "contribuinte      (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "tortura           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "reforma           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "armadilha         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "injustiça         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "colapso           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "marcha            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "amotinamiento     (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "encarar           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "comunidade        (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "operação          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "ganadeiro         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "posto             (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "decisão           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "                                 ...                \n",
       "presença          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "produtor          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "extremo           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "mineiro           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "autonomia         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "convite           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "pesquisa          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "Fernando          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "plantação         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "ativar            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "humilhar          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "cidadão           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "extracção         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "membro            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "participante      (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "incluir           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "problema          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "um                (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "intimidar         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "alteração         (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "guarani           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "vice              (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "vigília           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "perseguição       (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "perigo            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "relação           (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "desgosto          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "promotor          (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "rural             (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "manter            (2014, 12, 3, 0, 0, 0, 2, 337, -1)\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.idxmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[time.struct_time(tm_year=2014, tm_mon=12, tm_mday=3, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=2, tm_yday=337, tm_isdst=-1),\n",
       " time.struct_time(tm_year=2014, tm_mon=12, tm_mday=15, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=0, tm_yday=349, tm_isdst=-1),\n",
       " time.struct_time(tm_year=2014, tm_mon=12, tm_mday=16, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=1, tm_yday=350, tm_isdst=-1),\n",
       " time.struct_time(tm_year=2014, tm_mon=12, tm_mday=31, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=2, tm_yday=365, tm_isdst=-1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=2014, tm_mon=12, tm_mday=31, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=2, tm_yday=365, tm_isdst=-1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df1.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=2014, tm_mon=12, tm_mday=3, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=2, tm_yday=337, tm_isdst=-1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df1.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "range() integer end argument expected, got time.struct_time.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a5f2c90b1dc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: range() integer end argument expected, got time.struct_time."
     ]
    }
   ],
   "source": [
    "range(min(df1.index.values.tolist()),max(df1.index.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'time.struct_time' and 'time.struct_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d5cc427d283e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'time.struct_time' and 'time.struct_time'"
     ]
    }
   ],
   "source": [
    "max(df1.index.values.tolist()) - min(df1.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'time.struct_time' and 'time.struct_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7476a388f05b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'time.struct_time' and 'time.struct_time'"
     ]
    }
   ],
   "source": [
    "abs((max(df1.index.values.tolist()) - min(df1.index.values.tolist())).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'strptime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8877ffc70f39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-8877ffc70f39>\u001b[0m in \u001b[0;36mcreate_df\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'embersGeoCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Brazil'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0mdf_twitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mdf_aggregated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_twitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m#df.loc[df['date'].idxmax()]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'strptime'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "import datetime\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [datetime.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            medo  ataque  armar  emboscada  interrogatório  recrudescência  \\\n",
      "date                                                                         \n",
      "2014-12-03     0       0      0          0               0               0   \n",
      "2014-12-15     0       0      0          0               0               0   \n",
      "2014-12-16     0       0      0          0               0               0   \n",
      "2014-12-31     0       0      0          0               0               0   \n",
      "\n",
      "            oposição  essencial  cooperativa  pobreza   ...    guarani  vice  \\\n",
      "date                                                    ...                    \n",
      "2014-12-03         0          0            0        0   ...          0     0   \n",
      "2014-12-15         0          0            0        0   ...          0     0   \n",
      "2014-12-16         0          0            0        0   ...          0     0   \n",
      "2014-12-31         0          0            0        0   ...          0     0   \n",
      "\n",
      "            vigília  perseguição  perigo  relação  desgosto  promotor  rural  \\\n",
      "date                                                                           \n",
      "2014-12-03        0            0       0        0         0         0      0   \n",
      "2014-12-15        0            0       0        0         0         0      0   \n",
      "2014-12-16        0            0       0        0         0         0      0   \n",
      "2014-12-31        0            0       0        0         0         0      0   \n",
      "\n",
      "            manter  \n",
      "date                \n",
      "2014-12-03       0  \n",
      "2014-12-15       0  \n",
      "2014-12-16       0  \n",
      "2014-12-31       0  \n",
      "\n",
      "[4 rows x 624 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as js\n",
    "from datetime import datetime\n",
    "\n",
    "file_twitter = \"./sample.txt\"\n",
    "file_keys = \"./CU_Keywords.2013-01-25T15-36-29\"\n",
    "\n",
    "languages = ['English', 'Portuguese', 'Spanish']\n",
    "\n",
    "\n",
    "def get_keywords(f_key_dict):\n",
    "    dicts = {}\n",
    "    for lag in languages:\n",
    "        dicts[lag] = {}\n",
    "    for l in open(f_key_dict):\n",
    "        obj = js.loads(l)\n",
    "        lag = obj['language']\n",
    "        if lag in languages:\n",
    "            #word = obj['text']\n",
    "            lemma = obj['tokens'][0]['lemma']\n",
    "            dicts[lag][lemma] = True\n",
    "    return dicts\n",
    "\n",
    "\n",
    "def get_features(obj, language, keywords):\n",
    "    res = [key in obj['BasisEnrichment']['tokens'] for key in keywords]\n",
    "    return [int(r) for r in res]\n",
    "    \n",
    "        \n",
    "dicts = get_keywords(file_keys)\n",
    "\n",
    "\n",
    "def create_df(language):\n",
    "    keywords = list(dicts[language].keys())\n",
    "    df_twitter = pd.DataFrame(columns=(keywords + ['date']))\n",
    "    lines = open(file_twitter).readlines()\n",
    "    for i in range(len(lines)):\n",
    "        obj = js.loads(lines[i])\n",
    "        if obj['embersGeoCode']['country'] == 'Brazil':\n",
    "            df_twitter.loc[i] = get_features(obj,language,dicts[language]) + [datetime.strptime(obj['date'].split(\"T\")[0],'%Y-%m-%d')]\n",
    "    df_aggregated = df_twitter.groupby(\"date\").agg({key: np.sum for key in keywords})\n",
    "    #df.loc[df['date'].idxmax()]\n",
    "    return df_aggregated\n",
    "\n",
    "\n",
    "df1 = create_df(languages[1])\n",
    "print df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2419200000000000L"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df1.index.values.tolist()) - min(df1.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'long' object has no attribute 'days'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-dd87bcb5a716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'long' object has no attribute 'days'"
     ]
    }
   ],
   "source": [
    "(max(df1.index.values.tolist()) - min(df1.index.values.tolist())).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'long' object has no attribute 'days'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-157faf1456c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'long' object has no attribute 'days'"
     ]
    }
   ],
   "source": [
    "max(df1.index.values.tolist()) - min(df1.index.values.tolist()).days()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'long' object has no attribute 'days'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-dd87bcb5a716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'long' object has no attribute 'days'"
     ]
    }
   ],
   "source": [
    "(max(df1.index.values.tolist()) - min(df1.index.values.tolist())).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'timedelta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c0a92dedb7d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'timedelta'"
     ]
    }
   ],
   "source": [
    "max(df1.index.values.tolist())- datetime.timedelta(days=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'timedelta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-c0a92dedb7d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'timedelta'"
     ]
    }
   ],
   "source": [
    "max(df1.index.values.tolist())- datetime.timedelta(days=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-9c8434a30848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "max(df1.index.values.tolist())- timedelta(days=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'timedelta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-a0d3dfcd0d48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'timedelta'"
     ]
    }
   ],
   "source": [
    "max(df1.index.values.tolist())- datetime.timedelta(days=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'long' and 'datetime.timedelta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-85b07486bbfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'long' and 'datetime.timedelta'"
     ]
    }
   ],
   "source": [
    "max(df1.index.values.tolist())- timedelta(days=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419984000000000000L"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df1.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medo</th>\n",
       "      <th>ataque</th>\n",
       "      <th>armar</th>\n",
       "      <th>emboscada</th>\n",
       "      <th>interrogatório</th>\n",
       "      <th>recrudescência</th>\n",
       "      <th>oposição</th>\n",
       "      <th>essencial</th>\n",
       "      <th>cooperativa</th>\n",
       "      <th>pobreza</th>\n",
       "      <th>...</th>\n",
       "      <th>guarani</th>\n",
       "      <th>vice</th>\n",
       "      <th>vigília</th>\n",
       "      <th>perseguição</th>\n",
       "      <th>perigo</th>\n",
       "      <th>relação</th>\n",
       "      <th>desgosto</th>\n",
       "      <th>promotor</th>\n",
       "      <th>rural</th>\n",
       "      <th>manter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-03</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            medo  ataque  armar  emboscada  interrogatório  recrudescência  \\\n",
       "date                                                                         \n",
       "2014-12-03     0       0      0          0               0               0   \n",
       "2014-12-15     0       0      0          0               0               0   \n",
       "2014-12-16     0       0      0          0               0               0   \n",
       "2014-12-31     0       0      0          0               0               0   \n",
       "\n",
       "            oposição  essencial  cooperativa  pobreza   ...    guarani  vice  \\\n",
       "date                                                    ...                    \n",
       "2014-12-03         0          0            0        0   ...          0     0   \n",
       "2014-12-15         0          0            0        0   ...          0     0   \n",
       "2014-12-16         0          0            0        0   ...          0     0   \n",
       "2014-12-31         0          0            0        0   ...          0     0   \n",
       "\n",
       "            vigília  perseguição  perigo  relação  desgosto  promotor  rural  \\\n",
       "date                                                                           \n",
       "2014-12-03        0            0       0        0         0         0      0   \n",
       "2014-12-15        0            0       0        0         0         0      0   \n",
       "2014-12-16        0            0       0        0         0         0      0   \n",
       "2014-12-31        0            0       0        0         0         0      0   \n",
       "\n",
       "            manter  \n",
       "date                \n",
       "2014-12-03       0  \n",
       "2014-12-15       0  \n",
       "2014-12-16       0  \n",
       "2014-12-31       0  \n",
       "\n",
       "[4 rows x 624 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            medo  ataque  armar  emboscada  interrogatório  recrudescência  \\\n",
      "date                                                                         \n",
      "2014-12-03     0       0      0          0               0               0   \n",
      "2014-12-15     0       0      0          0               0               0   \n",
      "2014-12-16     0       0      0          0               0               0   \n",
      "2014-12-31     0       0      0          0               0               0   \n",
      "\n",
      "            oposição  essencial  cooperativa  pobreza   ...    guarani  vice  \\\n",
      "date                                                    ...                    \n",
      "2014-12-03         0          0            0        0   ...          0     0   \n",
      "2014-12-15         0          0            0        0   ...          0     0   \n",
      "2014-12-16         0          0            0        0   ...          0     0   \n",
      "2014-12-31         0          0            0        0   ...          0     0   \n",
      "\n",
      "            vigília  perseguição  perigo  relação  desgosto  promotor  rural  \\\n",
      "date                                                                           \n",
      "2014-12-03        0            0       0        0         0         0      0   \n",
      "2014-12-15        0            0       0        0         0         0      0   \n",
      "2014-12-16        0            0       0        0         0         0      0   \n",
      "2014-12-31        0            0       0        0         0         0      0   \n",
      "\n",
      "            manter  \n",
      "date                \n",
      "2014-12-03       0  \n",
      "2014-12-15       0  \n",
      "2014-12-16       0  \n",
      "2014-12-31       0  \n",
      "\n",
      "[4 rows x 624 columns]\n"
     ]
    }
   ],
   "source": [
    "print df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419984000000000000L"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df1.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "timestamp out of range for platform localtime()/gmtime() function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-978eddc768e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: timestamp out of range for platform localtime()/gmtime() function"
     ]
    }
   ],
   "source": [
    "datetime.fromtimestamp(max(df1.index.values.tolist())).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1417564800000000000L,\n",
       " 1418601600000000000L,\n",
       " 1418688000000000000L,\n",
       " 1419984000000000000L]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2014-12-02T19:00:00.000000000-0500',\n",
       "       '2014-12-14T19:00:00.000000000-0500',\n",
       "       '2014-12-15T19:00:00.000000000-0500',\n",
       "       '2014-12-30T19:00:00.000000000-0500'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2014-12-30T19:00:00.000000000-0500')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df1.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2014-12-02T19:00:00.000000000-0500')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df1.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.timedelta64(2419200000000000,'ns')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df1.index.values) - min(df1.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.timedelta64' object has no attribute 'days'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-3c95c8e8ddc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.timedelta64' object has no attribute 'days'"
     ]
    }
   ],
   "source": [
    "(max(df1.index.values) - min(df1.index.values)).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(max(df1.index.values) - min(df1.index.values))/np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
